# app_gradio.py
import gradio as gr
import os
import uuid
from typing import Optional
import tempfile
import re # Import regular expression module for cleaning text

# Import helper functions and the LangGraph application builder
from utils import upload_to_gcs, download_from_gcs, delete_gcs_blob, GCS_BUCKET_NAME
from agent_graph import build_public_speaking_coach_graph
from agent_nodes import PublicSpeakingState # Import the state class for type hinting

# Initialize the LangGraph application once when the Gradio app starts
public_speaking_coach_app = build_public_speaking_coach_graph()

# --- Gradio Interface Function ---
async def get_speech_feedback(video_file_path: str) -> tuple[str, Optional[str], gr.HTML, gr.Button, gr.Markdown]:
    """
    Gradio function to handle video upload/recording, trigger the AI coach workflow,
    and return textual and audio feedback, along with updates for UI components.

    Args:
        video_file_path (str): The local temporary path to the uploaded/recorded video file
                                provided by Gradio.

    Returns:
        tuple[str, Optional[str], gr.HTML, gr.Button, gr.Markdown]: A tuple containing:
            - The textual feedback from the AI coach.
            - The local path to the synthesized audio feedback file (for Gradio playback),
              or None if audio synthesis failed.
            - Update for loading_indicator (hide).
            - Update for submit_button (enable).
            - Update for audio_placeholder (hide).
    """
    # Initial state for UI components (hidden loading, disabled button)
    # Note: These are base states for updates, not the actual components themselves
    initial_loading_state_html = """<div id="loadingIndicator" class="mt-4 text-center text-blue-600 font-medium hidden">
            <div class="animate-spin inline-block w-6 h-6 border-4 border-blue-500 border-t-transparent rounded-full"></div>
            Processing video and generating feedback...
        </div>"""
    initial_button_label = "Get Coaching Feedback"
    initial_audio_placeholder_html = "<p id='audioPlaceholder' class='text-gray-500 text-sm italic mt-2'>Audio feedback will appear here once generated.</p>"


    if video_file_path is None:
        gr.Warning("Please upload or record a video first.")
        # FIX: Use yield instead of return for async generator
        yield "No video provided.", None, \
              gr.HTML(initial_loading_state_html, visible=False), \
              gr.Button(initial_button_label, variant="primary", elem_classes="mt-5", interactive=False), \
              gr.Markdown(initial_audio_placeholder_html, visible=True)
        return # Exit the generator

    print(f"Received video file at: {video_file_path}")

    # Generate a unique ID for this session to manage files
    session_id = uuid.uuid4().hex
    gcs_video_blob_name = f"user_uploads/{session_id}_input_video.mp4"
    
    # Use tempfile.gettempdir() to ensure the audio file is saved in Gradio's expected temp directory
    local_feedback_audio_path = os.path.join(tempfile.gettempdir(), f"{session_id}_final_feedback.mp3")

    # Initialize GCS URIs for cleanup in finally block
    video_gcs_uri = None
    extracted_audio_gcs_uri = None
    feedback_audio_gcs_uri = None

    try:
        # Update UI to show loading and disable button
        yield "", None, \
              gr.HTML(initial_loading_state_html, visible=True), \
              gr.Button("Processing...", variant="primary", elem_classes="mt-5", interactive=False), \
              gr.Markdown(initial_audio_placeholder_html, visible=True)

        # 1. Upload the user's video to Google Cloud Storage
        print(f"Uploading video '{video_file_path}' to GCS...")
        video_gcs_uri = upload_to_gcs(video_file_path, gcs_video_blob_name)
        print(f"Video uploaded to GCS: {video_gcs_uri}")

        # 2. Prepare the initial state for the LangGraph agent
        initial_state = PublicSpeakingState(video_gcs_uri=video_gcs_uri)

        # 3. Run the LangGraph agent workflow
        print(f"Starting LangGraph agent for session: {session_id}")
        
        # Correctly extract the final state from the LangGraph stream
        final_state_output = None
        for s in public_speaking_coach_app.stream(initial_state):
            if 'synthesize_audio_feedback' in s:
                final_state_output = s['synthesize_audio_feedback']

        if not final_state_output:
            raise gr.Error("LangGraph agent did not produce a final state containing audio feedback.")

        # 4. Extract feedback from the final state of the graph
        feedback_text = final_state_output.get('feedback_text', 'No textual feedback generated by the AI coach.')
        feedback_audio_gcs_uri = final_state_output.get('feedback_audio_gcs_uri')
        extracted_audio_gcs_uri = final_state_output.get('extracted_audio_gcs_uri') # For cleanup

        # DEBUGGING: Print the extracted audio URI value
        print(f"DEBUG: Extracted feedback_audio_gcs_uri: {feedback_audio_gcs_uri}")

        if not feedback_audio_gcs_uri:
            raise gr.Error("Failed to generate audio feedback from Text-to-Speech.")

        # 5. Download the synthesized audio feedback from GCS for Gradio to play
        print(f"Downloading audio feedback from GCS: {feedback_audio_gcs_uri}")
        download_from_gcs(feedback_audio_gcs_uri, local_feedback_audio_path)
        print(f"Audio feedback downloaded to: {local_feedback_audio_path}")

        print(f"Session {session_id} complete. Returning feedback.")
        
        # Return all 5 outputs for the components
        yield feedback_text, local_feedback_audio_path, \
              gr.HTML(initial_loading_state_html, visible=False), \
              gr.Button(initial_button_label, variant="primary", elem_classes="mt-5", interactive=True), \
              gr.Markdown(initial_audio_placeholder_html, visible=False)

    except Exception as e:
        error_message = f"An error occurred during feedback generation: {e}"
        print(error_message)
        import traceback
        traceback.print_exc() # Print full traceback for detailed debugging in console
        gr.Error(error_message + " Please check the console for details.")
        # Ensure all 5 outputs are returned even on error
        yield "An error occurred. Please try again or check the server logs for more information.", \
               None, \
               gr.HTML(initial_loading_state_html, visible=False), \
               gr.Button(initial_button_label, variant="primary", elem_classes="mt-5", interactive=True), \
               gr.Markdown(initial_audio_placeholder_html, visible=True)
    finally:
        # --- Cleanup Temporary Files ---
        # It's crucial to clean up files to manage storage costs and disk space.

        # Delete original uploaded video from GCS
        if video_gcs_uri:
            delete_gcs_blob(video_gcs_uri)
        # Delete extracted audio from GCS
        if extracted_audio_gcs_uri:
            delete_gcs_blob(extracted_audio_gcs_uri)
        # Delete synthesized audio feedback from GCS
        if feedback_audio_gcs_uri:
            delete_gcs_blob(feedback_audio_gcs_uri)

        # Delete local temporary files created by Gradio and during processing
        if os.path.exists(video_file_path):
            os.remove(video_file_path)
            print(f"Cleaned up local video file: {video_file_path}")
        # IMPORTANT: Do NOT remove local_feedback_audio_path here if Gradio needs it for playback
        # Gradio will manage cleanup of files it's responsible for.
        # If the file is still there after the app closes, it's fine for debugging.
        # if os.path.exists(local_feedback_audio_path):
        #     os.remove(local_feedback_audio_path)
        #     print(f"Cleaned up local audio file: {local_feedback_audio_path}")

# --- Custom CSS for Gradio UI improvements ---
custom_css = """
/* Import Inter font */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

body {
    font-family: 'Inter', sans-serif !important;
    background-color: #f0f4f8 !important; /* Light blue-gray background */
}

/* Main Gradio block styling */
.gradio-container {
    background-color: #ffffff !important;
    border-radius: 1rem !important; /* rounded-xl */
    box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05) !important; /* shadow-lg */
    padding: 1.5rem !important; /* p-6 */
    max-width: 48rem !important; /* md:max-w-lg lg:max-w-xl equivalent */
    width: 100% !important;
    margin: auto !important; /* Center the container */
}

/* Headings */
h1 {
    font-size: 2.25rem !important; /* text-3xl */
    font-weight: 700 !important; /* font-bold */
    text-align: center !important;
    color: #1f2937 !important; /* text-gray-800 */
    margin-bottom: 1.5rem !important; /* mb-6 */
}

p {
    text-align: center !important;
    color: #4b5563 !important; /* text-gray-600 */
    margin-bottom: 2rem !important; /* mb-8 */
}

/* Section Containers */
.section-container {
    background-color: #eff6ff !important; /* bg-blue-50, bg-green-50, bg-purple-50 */
    border-radius: 0.5rem !important; /* rounded-lg */
    border-width: 1px !important;
    padding: 1rem !important; /* p-4 */
    margin-bottom: 2rem !important; /* mb-8 */
}
.section-blue { border-color: #bfdbfe !important; /* border-blue-200 */ }
.section-green { border-color: #d1fae5 !important; /* border-green-200 */ }
.section-purple { border-color: #e9d5ff !important; /* border-purple-200 */ }

/* Section Headings */
.section-heading {
    font-size: 1.125rem !important; /* text-lg */
    font-weight: 500 !important; /* font-medium */
    margin-bottom: 0.75rem !important; /* mb-3 */
}
.section-heading-blue { color: #1e40af !important; /* text-blue-800 */ }
.section-heading-green { color: #065f46 !important; /* text-green-800 */ }
.section-heading-purple { color: #6b21a8 !important; /* text-purple-800 */ }


/* Input and Video Preview */
.gr-video-upload-button, .gr-file-input {
    border-radius: 0.375rem !important; /* rounded-md */
    border-color: #d1d5db !important; /* border-gray-300 */
    box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05) !important; /* shadow-sm */
    color: #374151 !important; /* text-gray-700 */
}
.gr-video-container video {
    border-radius: 0.375rem !important; /* rounded-md */
    box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05) !important; /* shadow-sm */
    margin-top: 1rem !important; /* mt-4 */
}

/* Submit Button */
.gr-button.gr-button-primary {
    background-color: #2563eb !important; /* bg-blue-600 */
    color: #ffffff !important; /* text-white */
    font-weight: 600 !important; /* font-semibold */
    padding-top: 0.75rem !important; /* py-3 */
    padding-bottom: 0.75rem !important; /* py-3 */
    padding-left: 1rem !important; /* px-4 */
    padding-right: 1rem !important; /* px-4 */
    border-radius: 0.5rem !important; /* rounded-lg */
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06) !important; /* shadow-md */
    transition: all 0.3s ease-in-out !important;
    transform: scale(1) !important;
    margin-top: 1.25rem !important; /* mt-5 */
    width: 100% !important; /* w-full */
}
.gr-button.gr-button-primary:hover {
    background-color: #1d4ed8 !important; /* hover:bg-blue-700 */
    transform: scale(1.05) !important; /* hover:scale-105 */
}
.gr-button.gr-button-primary:focus {
    outline: 2px solid transparent !important;
    outline-offset: 2px !important;
    box-shadow: 0 0 0 2px #ffffff, 0 0 0 4px #3b82f6 !important; /* focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 */
}
.gr-button.gr-button-primary:disabled {
    opacity: 0.6 !important;
    cursor: not-allowed !important;
    transform: none !important;
}

/* Loading Indicator */
#loadingIndicator {
    text-align: center !important;
    color: #2563eb !important; /* text-blue-600 */
    font-weight: 500 !important; /* font-medium */
    margin-top: 1rem !important; /* mt-4 */
}
#loadingIndicator div { /* Spinner */
    display: inline-block !important;
    width: 1.5rem !important; /* w-6 */
    height: 1.5rem !important; /* h-6 */
    border-width: 4px !important; /* border-4 */
    border-color: #3b82f6 !important; /* border-blue-500 */
    border-top-color: transparent !important; /* border-t-transparent */
    border-radius: 9999px !important; /* rounded-full */
    animation: spin 1s linear infinite;
}
@keyframes spin {
    from { transform: rotate(0deg); }
    to { transform: rotate(360deg); }
}

/* Audio Player */
.gr-audio-container audio {
    border-radius: 0.375rem !important; /* rounded-md */
    box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05) !important; /* shadow-sm */
}
#audioPlaceholder {
    color: #6b7280 !important; /* text-gray-500 */
    font-style: italic !important;
    font-size: 0.875rem !important; /* text-sm */
    margin-top: 0.5rem !important; /* mt-2 */
}

/* Text Feedback Area */
#textFeedback {
    background-color: #ffffff !important; /* bg-white */
    padding: 1rem !important; /* p-4 */
    border-radius: 0.375rem !important; /* rounded-md */
    border-width: 1px !important;
    border-color: #d1d5db !important; /* border-gray-300 */
    height: 12rem !important; /* h-48 */
    overflow-y: auto !important;
    color: #374151 !important; /* text-gray-700 */
    line-height: 1.625 !important; /* leading-relaxed */
    box-shadow: inset 0 2px 4px 0 rgba(0, 0, 0, 0.06) !important; /* shadow-inner */
}

/* Markdown bolding */
#textFeedback strong {
    font-weight: 600 !important; /* Make bold text stand out */
    color: #1f2937 !important; /* Darker color for bold */
}

/* Gradio's internal row/column adjustments for responsiveness */
.gradio-row {
    flex-wrap: wrap !important; /* Allow rows to wrap on small screens */
}
.gradio-column {
    flex: 1 1 100% !important; /* Full width on small screens */
    min-width: 0 !important; /* Prevent overflow */
}

/* Adjust column behavior for larger screens */
@media (min-width: 768px) { /* md breakpoint */
    .gradio-column {
        flex: 1 1 0% !important; /* Equal width on larger screens */
    }
}
"""

# --- Gradio Interface Definition ---
with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo: # Using Soft theme and injecting custom CSS
    gr.Markdown("# 🗣️ AI Public Speaking Coach", elem_classes="text-center")
    gr.Markdown(
        "Upload or record a **10 to 60-second video** of your public speaking. "
        "Our AI coach will analyze your speech and provide personalized audio feedback!"
    )

    # Video Recording/Upload Section
    with gr.Column(elem_classes="section-container section-blue"):
        gr.Markdown("<h2 class='section-heading section-heading-blue'>1. Record or Upload Your Video</h2>")
        video_input = gr.Video(
            label="Your Public Speaking Video",
            sources=["upload", "webcam"],
            format="mp4",
            height=300,
            width=500, # Max width for consistency
            elem_classes="rounded-md shadow-sm"
        )
        # FIX: Set submit_button to be interactive=False by default
        submit_button = gr.Button("Get Coaching Feedback", variant="primary", elem_classes="mt-5", interactive=False)
        loading_indicator = gr.HTML("""
            <div id="loadingIndicator" class="mt-4 text-center text-blue-600 font-medium hidden">
                <div class="animate-spin inline-block w-6 h-6 border-4 border-blue-500 border-t-transparent rounded-full"></div>
                Processing video and generating feedback...
            </div>
        """)

    # Audio Feedback Section
    with gr.Column(elem_classes="section-container section-green"):
        gr.Markdown("<h2 class='section-heading section-heading-green'>2. Audio Feedback</h2>")
        audio_output = gr.Audio(
            label="Audio Feedback from AI Coach",
            interactive=False,
            autoplay=True,
            type="filepath",
            elem_classes="rounded-md shadow-sm"
        )
        audio_placeholder = gr.Markdown("<p id='audioPlaceholder' class='text-gray-500 text-sm italic mt-2'>Audio feedback will appear here once generated.</p>")

    # Text Feedback Section
    with gr.Column(elem_classes="section-container section-purple"):
        gr.Markdown("<h2 class='section-heading section-heading-purple'>3. Textual Feedback</h2>")
        # Changed to gr.Markdown for proper rendering of bold text
        text_output = gr.Markdown(
            value="Your detailed textual feedback will appear here. It will include strengths, areas for improvement, and overall encouragement.",
            # Removed interactive=False as gr.Markdown does not support it
            elem_id="textFeedback", # Use elem_id to target with custom CSS
            elem_classes="bg-white p-4 rounded-md border border-gray-300 h-48 overflow-y-auto text-gray-700 leading-relaxed shadow-inner"
        )

    # Define the interaction: when submit_button is clicked, call get_speech_feedback
    # and update text_output and audio_output.
    submit_button.click(
        fn=get_speech_feedback,
        inputs=[video_input],
        outputs=[text_output, audio_output, loading_indicator, submit_button, audio_placeholder], # Also update loading and button
        queue=True,
        api_name="get_public_speaking_feedback",
        # Show loading indicator and disable button during processing
        # This is handled by JavaScript in the HTML version, but Gradio can do it via state
        # The outputs for loading_indicator and submit_button will be updated by the fn
    )

    # FIX: Add a change event listener to video_input to enable/disable the submit_button
    video_input.change(
        fn=lambda x: gr.Button(interactive=x is not None),
        inputs=[video_input],
        outputs=[submit_button],
        queue=False # This should be fast, no need to queue
    )


    # JS for managing loading state and initial placeholder text
    demo.load(js="""
        () => {
            const submitBtn = document.querySelector('.gr-button.gr-button-primary'); // Select by class as id is not directly accessible here
            const loadingDiv = document.querySelector('#loadingIndicator');
            const audioPh = document.querySelector('#audioPlaceholder');
            
            // Initial state: hide loading, show placeholder
            if (loadingDiv) loadingDiv.style.display = 'none';
            if (audioPh) audioPh.style.display = 'block';

            // Add event listener to the submit button to show loading and disable button
            // This is a workaround as Gradio's direct updates for these are after the function call
            if (submitBtn) {
                submitBtn.addEventListener('click', () => {
                    if (loadingDiv) loadingDiv.style.display = 'block';
                    if (submitBtn) submitBtn.disabled = true; // Disable button
                    if (audioPh) audioPh.style.display = 'block'; // Ensure placeholder is visible during processing
                    // Reset text output to processing message
                    const textOutputElement = document.querySelector('#textFeedback');
                    if (textOutputElement) textOutputElement.innerHTML = 'Processing video and generating feedback...';
                });
            }

            // Observe changes to the audio output to hide placeholder
            const audioOutputElement = document.querySelector('audio[id="audioFeedback"]'); // Select audio element more specifically
            if (audioOutputElement) {
                const observer = new MutationObserver((mutations) => {
                    mutations.forEach((mutation) => {
                        if (mutation.attributeName === 'src' && audioOutputElement.src && audioOutputElement.src !== window.location.href) {
                            // Check if src is set and not just the current page URL (which is default for empty src)
                            if (audioPh) audioPh.style.display = 'none';
                        }
                    });
                });
                observer.observe(audioOutputElement, { attributes: true });
            }

            return []; // No initial outputs
        }
    """)

# --- Main execution block ---
if __name__ == "__main__":
    print(f"Temporary directory '{tempfile.gettempdir()}' ensured to exist: {os.path.exists(tempfile.gettempdir())}")

    print("\nLaunching Gradio app...")
    # FIX: Ensure Gradio binds to 0.0.0.0 inside the container for external access
    demo.launch(share=True, server_name="0.0.0.0") # <<< ADDED server_name="0.0.0.0"
    print("Gradio app launched. Check your console for the public URL.")
